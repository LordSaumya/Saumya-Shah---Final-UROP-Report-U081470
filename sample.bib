@techreport{Udrescu2020,
abstract = {A core challenge for both physics and artificial intelligence (AI) is symbolic regression: finding a symbolic expression that matches data from an unknown function. Although this problem is likely to be NP-hard in principle, functions of practical interest often exhibit symmetries, separability, compositionality, and other simplifying properties. In this spirit, we develop a recursive multidimensional symbolic regression algorithm that combines neural network fitting with a suite of physics-inspired techniques. We apply it to 100 equations from the Feynman Lectures on Physics, and it discovers all of them, while previous publicly available software cracks only 71; for a more difficult physics-based test set, we improve the state-of-the-art success rate from 15 to 90%.},
author = {Udrescu, Silviu-Marian and Tegmark, Max},
title = {{AI Feynman: A physics-inspired method for symbolic regression}},
url = {https://www.science.org},
year = {2020}
}

@BOOK{Karttunen2016-gt,
  title     = "Fundamental Astronomy",
  editor    = "Karttunen, Hannu and Kroger, Pekka and Oja, Heikki and Poutanen, Markku and Donner, Karl Johan",
  publisher = "Springer",
  edition   =  6,
  month     =  nov,
  year      =  2016,
  address   = "Berlin, Germany",
  language  = "en"
}

@incollection{Khoo2023.1,
author = {Khoo, Zi-Yu and Rajiv, Gokul and Yang, Abel and Low, Jonathan Sze Choong and Bressan, St{\'{e}}phane},
doi = {10.1007/978-3-031-48316-5_21},
keywords = {machine learning,pareto optimisation,symbolic regression},
mendeley-groups = {UROP},
pages = {201--207},
title = {{Celestial Machine Learning: Discovering the Planarity, Heliocentricity, and Orbital Equation of Mars with AI Feynman}},
url = {https://link.springer.com/10.1007/978-3-031-48316-5_21},
year = {2023}
}

@article{Lemos2023,
abstract = {We present an approach for using machine learning to automatically discover the governing equations and unknown properties (in this case, masses) of real physical systems from observations. We train a â€˜graph neural network' to simulate the dynamics of our Solar System's Sun, planets, and large moons from 30 years of trajectory data. We then use symbolic regression to correctly infer an analytical expression for the force law implicitly learned by the neural network, which our results showed is equivalent to Newton's law of gravitation. The key assumptions our method makes are translational and rotational equivariance, and Newton's second and third laws of motion. It did not, however, require any assumptions about the masses of planets and moons or physical constants, but nonetheless, they, too, were accurately inferred with our method. Naturally, the classical law of gravitation has been known since Isaac Newton, but our results demonstrate that our method can discover unknown laws and hidden properties from observed data.},
archivePrefix = {arXiv},
arxivId = {2202.02306},
author = {Lemos, Pablo and Jeffrey, Niall and Cranmer, Miles and Ho, Shirley and Battaglia, Peter},
doi = {10.1088/2632-2153/acfa63},
eprint = {2202.02306},
journal = {Machine Learning: Science and Technology},
number = {4},
pages = {045002},
title = {{Rediscovering orbital mechanics with machine learning}},
volume = {4},
year = {2023}
}

@article{Brunton2016,
author = {Brunton, Steven L and Proctor, Joshua L and Kutz, J Nathan},
doi = {10.1073/pnas.1517384113},
file = {:C\:/Users/Saumya/Downloads/UROP/References/brunton-et-al-2016-discovering-governing-equations-from-data-by-sparse-identification-of-nonlinear-dynamical-systems.pdf:pdf},
number = {15},
pages = {3932--3937},
title = {{Discovering governing equations from data by sparse identification of nonlinear dynamical systems}},
volume = {113},
year = {2016}
}

@incollection{Khoo2023.2,
author = {Khoo, Zi-Yu and Yang, Abel and Low, Jonathan Sze Choong and Bressan, St{\'{e}}phane},
doi = {10.1007/978-3-031-39821-6_41},
file = {:C\:/Users/Saumya/Downloads/UROP/References/DEXA_2023__Celestial_Machine_Learning.pdf:pdf},
pages = {469--474},
title = {{Celestial Machine Learning: From Data to Mars and Beyond with AI Feynman}},
url = {https://www.researchgate.net/publication/373146780_Celestial_Machine_Learning_From_Data_to_Mars_and_Beyond_with_AI_Feynman https://link.springer.com/10.1007/978-3-031-39821-6_41},
year = {2023}
}

@book{brown1896introductory,
  title={An Introductory Treatise on the Lunar Theory},
  author={Brown, E.W.},
  lccn={02122233},
  year={1896},
  publisher={The University Press}
}

@ARTICLE{1967PASP...79..482T,
       author = {{Thoren}, Victor E.},
        title = "{TYCHO and Kepler on the Lunar Theory}",
      journal = {PASP},
         year = 1967,
        month = oct,
       volume = {79},
       number = {470},
        pages = {482},
          doi = {10.1086/128534},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{burgay2012parkes,
  author = {Burgay, M. and Possenti, A. and Manchester, R. and Kramer, M. and Lyne, A. and McLaughlin, M. and et al.},
  title = {Parkes observations for project P455 semester 2011OCTS. v2},
  publisher = {CSIRO},
  year = {2012},
  doi = {10.4225/08/524992DBB978D},
}

@book{kepler1609astronomia,
author={Kepler, Johannes and Donahue, W. H.},
title={New Astronomy},
year={1992},
publisher={Cambridge University Press},
annotation="English translation by William H. Donahue"
}

@misc{oh2023geneticprogrammingbasedsymbolic,
      title={Genetic Programming Based Symbolic Regression for Analytical Solutions to Differential Equations}, 
      author={Hongsup Oh and Roman Amici and Geoffrey Bomarito and Shandian Zhe and Robert Kirby and Jacob Hochhalter},
      year={2023},
      eprint={2302.03175},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.03175}, 
}

@misc{makke2023interpretablescientificdiscoverysymbolic,
      title={Interpretable Scientific Discovery with Symbolic Regression: A Review}, 
      author={Nour Makke and Sanjay Chawla},
      year={2023},
      eprint={2211.10873},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.10873}, 
}

@article{Karniadakis,
title = "Physics-informed machine learning",
abstract = "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.",
author = "Karniadakis, {George Em} and Kevrekidis, {Ioannis G.} and Lu Lu and Paris Perdikaris and Sifan Wang and Liu Yang",
note = "Publisher Copyright: {\textcopyright} 2021, Springer Nature Limited.",
year = "2021",
month = jun,
doi = "10.1038/s42254-021-00314-5",
language = "English (US)",
volume = "3",
pages = "422--440",
journal = "Nature Reviews Physics",
issn = "2522-5820",
publisher = "Springer Nature Switzerland AG",
number = "6",
}